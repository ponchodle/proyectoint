{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6d2a7390",
      "metadata": {
        "id": "6d2a7390"
      },
      "source": [
        "# **Instituto Tecnológico y de Estudios superiores de Monterrey**\n",
        "\n",
        "## Escuela de Ingeniería y Ciencias\n",
        "\n",
        "### Maestría en inteligencia artificial aplicada\n",
        "\n",
        "#### Proyecto integrador\n",
        "\n",
        "*Avance 3*\n",
        "\n",
        "Alumnos:  \n",
        "Alfonso de Lucas Espinosa - A01795118  \n",
        "Pablo Andrés Estrada Flores - A01795212\n",
        "\n",
        "\n",
        "#### Desarrollo\n",
        "\n",
        "**1. ¿Qué algoritmo se puede utilizar como baseline para predecir las variables objetivo?**\n",
        "\n",
        "El algoritmo seleccionado como punto de partida  baseline para predecir las letras de la Lengua de Señas Mexicana (LSM) es una Red Neuronal Convolucional (CNN). La idoneidad de este algoritmo se fundamenta en varios aspectos clave del problema y los datos:\n",
        "\n",
        "1.1 Tipo y Estructura de los Datos:\n",
        "\n",
        "  Los datos de entrada consisten en las coordenadas (x, y, z) de 21 puntos de referencia (landmarks) de la mano, extraídos mediante MediaPipe.\n",
        "\n",
        "\n",
        "1.2 Cantidad de Datos:\n",
        "\n",
        "  El conjunto de datos es considerable. Por ejemplo, el conjunto de prueba contiene 55,231 muestras. Esta magnitud es adecuada para entrenar una CNN de manera efectiva, permitiéndole aprender patrones complejos sin un sobreajuste inmediato, especialmente con la división adecuada en conjuntos de entrenamiento, validación y prueba (60%/20%/20% respectivamente).\n",
        "\n",
        "1.3 Aprendizaje Automático de Características Relevantes:\n",
        "\n",
        "  Las CNN son capaces de aprender jerarquías de características espaciales directamente de los datos crudos o mínimamente procesados. En este caso, pueden identificar patrones relevantes en la disposición tridimensional de los landmarks de la mano para cada seña. Esta capacidad reduce la necesidad de ingeniería de características manual (como ángulos específicos o distancias precalculadas).\n",
        "\n",
        "1.4 Rendimiento en Tareas Similares:\n",
        "\n",
        "  La elección se respalda en el desempeño significativamente superior que las CNN han demostrado en tareas similares de clasificación de lenguas de señas, particularmente cuando se utiliza MediaPipe para la extracción de información de la mano.\n",
        "\n",
        "1.5 Interpretabilidad vs. Precisión:\n",
        "\n",
        "  Si bien la interpretabilidad directa de las características aprendidas por las capas convolucionales puede ser compleja, el objetivo principal en este contexto es la alta precisión en la clasificación de las señas. El modelo CNN propuesto, está diseñado para maximizar esta precisión.\n",
        "  Por estas razones, una CNN se considera un baseline fuerte y apropiado, ya que está bien adaptada a la naturaleza espacial y estructurada de los datos de landmarks de la mano y ha demostrado éxito en dominios análogos.\n",
        "\n",
        "**2. ¿Se puede determinar la importancia de las características para el modelo generado?**\n",
        "\n",
        "Las características geométricas han probado ser un apoyo clave en el desarrollo de modelos tradicionales de aprendizaje automático, como lo demuestra el trabajo de Anzar, H. (2022), donde se utiliza una combinación de estructuras K-ary tree y hashing para la identificación de gestos de la mano.\n",
        "\n",
        "No obstante, dichas características pueden afectar negativamente el desempeño de una CNN, ya que este tipo de red es capaz de aprender patrones espaciales de forma automática, requiriendo únicamente datos estructurados y, como mucho, normalizados para esta aplicación.\n",
        "\n",
        "Procedemos entonces con la generación de nuestro modelo CNN básico utilizando la librería PyTorch.\n",
        "\n",
        "#### Carga de paqueterías"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbbippTwe2zT",
        "outputId": "6539210e-dd44-4d20-96f3-a510c1315868"
      },
      "id": "MbbippTwe2zT",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cbff77c1",
      "metadata": {
        "id": "cbff77c1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df94fbf9",
      "metadata": {
        "id": "df94fbf9"
      },
      "source": [
        "#### Carga el procesamiento de datos; separación en conjuntos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d7b21d31",
      "metadata": {
        "id": "d7b21d31"
      },
      "outputs": [],
      "source": [
        "# Función para leer y preprocesar CSV\n",
        "def prepare_for_cnn_from_csv(path_csv):\n",
        "    df = pd.read_csv(path_csv)\n",
        "    X = df.drop(columns=['label']).values.reshape(-1, 21, 3)\n",
        "    y = df['label'].values\n",
        "\n",
        "    # Normalización espacial\n",
        "    wrist = X[:, 0:1, :]\n",
        "    X -= wrist\n",
        "    distances = np.linalg.norm(X[:, 1:, :], axis=2)\n",
        "    scale = np.mean(distances, axis=1, keepdims=True) + 1e-6\n",
        "    X[:, 1:, :] /= scale[:, np.newaxis]\n",
        "\n",
        "    # Codificar etiquetas\n",
        "    encoder = LabelEncoder()\n",
        "    y_encoded = encoder.fit_transform(y)\n",
        "\n",
        "    return X.astype(np.float32), y_encoded.astype(np.longlong), encoder\n",
        "\n",
        "# Ruta local del CSV\n",
        "csv_path = \"/content/drive/MyDrive/Colab Notebooks/LSM/03avance/hand_landmarks_raw.csv\"\n",
        "X, y, label_encoder = prepare_for_cnn_from_csv(csv_path)\n",
        "\n",
        "# Separar en train/val/test (60% train, 20% val, 20% test)\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, stratify=y_temp, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eca47740",
      "metadata": {
        "id": "eca47740"
      },
      "source": [
        "#### Adaptación del dataset a PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f6df8914",
      "metadata": {
        "id": "f6df8914"
      },
      "outputs": [],
      "source": [
        "class HandLandmarksDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X)\n",
        "        self.y = torch.tensor(y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_dataset = HandLandmarksDataset(X_train, y_train)\n",
        "val_dataset = HandLandmarksDataset(X_val, y_val)\n",
        "test_dataset = HandLandmarksDataset(X_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc5ee376",
      "metadata": {
        "id": "cc5ee376"
      },
      "source": [
        "#### Carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a264a6cd",
      "metadata": {
        "id": "a264a6cd"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82afd663",
      "metadata": {
        "id": "82afd663"
      },
      "source": [
        "#### Definición del modelo\n",
        "\n",
        "El modelo obtiene un tensor de forma (32, 21, 3), donde 32 es el tamaño del batch definido en el data loader, 21 es el número de puntos de la mano y 3 son las dimensiones de cada punto (x, y, z).\n",
        "Tiene dos capas Convid1d que ocupan la función de activación ReLU  seguidas de AdaptiveMaxPool que dan salida a un vector de logits de tamaño igual al número de letras (clases))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "ae9ebb73",
      "metadata": {
        "id": "ae9ebb73"
      },
      "outputs": [],
      "source": [
        "class LandmarkCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv1d(in_channels=3, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv1d(64, 128, kernel_size=3, padding=1)\n",
        "        self.pool = nn.AdaptiveMaxPool1d(1)\n",
        "        self.fc1 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.permute(0, 2, 1)  # (batch, 3, 21)\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = self.pool(x).squeeze(-1)\n",
        "        return self.fc1(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c96c8e3b",
      "metadata": {
        "id": "c96c8e3b"
      },
      "source": [
        "#### Entrenamiento\n",
        "\n",
        "Se entrena el modelo y se evaluan los conjuntos de train y val, para valorar un posible sub/sobre ajuste inicial. Se realiza en 10 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "aadd86fb",
      "metadata": {
        "id": "aadd86fb",
        "outputId": "0bf32c71-661d-4cb3-e96c-93379b753d3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 - Train Acc: 0.9199 - Val Acc: 0.9172 - Val Loss: 0.2607\n",
            "Epoch 2/10 - Train Acc: 0.9412 - Val Acc: 0.9387 - Val Loss: 0.1819\n",
            "Epoch 3/10 - Train Acc: 0.9554 - Val Acc: 0.9527 - Val Loss: 0.1447\n",
            "Epoch 4/10 - Train Acc: 0.9664 - Val Acc: 0.9650 - Val Loss: 0.1043\n",
            "Epoch 5/10 - Train Acc: 0.9728 - Val Acc: 0.9699 - Val Loss: 0.0941\n",
            "Epoch 6/10 - Train Acc: 0.9733 - Val Acc: 0.9710 - Val Loss: 0.0902\n",
            "Epoch 7/10 - Train Acc: 0.9709 - Val Acc: 0.9692 - Val Loss: 0.0928\n",
            "Epoch 8/10 - Train Acc: 0.9773 - Val Acc: 0.9752 - Val Loss: 0.0742\n",
            "Epoch 9/10 - Train Acc: 0.9757 - Val Acc: 0.9737 - Val Loss: 0.0746\n",
            "Epoch 10/10 - Train Acc: 0.9810 - Val Acc: 0.9778 - Val Loss: 0.0662\n"
          ]
        }
      ],
      "source": [
        "model = LandmarkCNN(num_classes=len(label_encoder.classes_))\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_X)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Evaluación en entrenamiento\n",
        "    model.eval()\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_X, batch_y in train_loader:\n",
        "            outputs = model(batch_X)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            train_correct += (preds == batch_y).sum().item()\n",
        "            train_total += batch_y.size(0)\n",
        "    train_acc = train_correct / train_total\n",
        "\n",
        "    # Evaluación en validación\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for batch_X, batch_y in val_loader:\n",
        "            outputs = model(batch_X)\n",
        "            loss = criterion(outputs, batch_y)\n",
        "            preds = torch.argmax(outputs, dim=1)\n",
        "            val_correct += (preds == batch_y).sum().item()\n",
        "            val_total += batch_y.size(0)\n",
        "            val_loss += loss.item()\n",
        "    val_acc = val_correct / val_total\n",
        "    val_loss_avg = val_loss / len(val_loader)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs} - Train Acc: {train_acc:.4f} - Val Acc: {val_acc:.4f} - Val Loss: {val_loss_avg:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0ed38ce",
      "metadata": {
        "id": "d0ed38ce"
      },
      "source": [
        "#### Evaluación\n",
        "\n",
        "Se evalúa el conjunto test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6314328d",
      "metadata": {
        "id": "6314328d",
        "outputId": "412ae579-8916-4052-c224-3701ba7c0aa7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluación en el conjunto de prueba:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.98      1.00      0.99      2764\n",
            "           B       1.00      0.99      0.99      2733\n",
            "           C       1.00      1.00      1.00      2578\n",
            "           D       0.99      0.96      0.98      2692\n",
            "           E       0.97      0.99      0.98      2692\n",
            "           F       0.98      0.99      0.99      2713\n",
            "           G       0.99      1.00      0.99      2595\n",
            "           H       1.00      0.99      0.99      2455\n",
            "           I       1.00      0.98      0.99      2696\n",
            "           L       1.00      0.99      0.99      2685\n",
            "           M       0.96      0.95      0.96      2601\n",
            "           N       0.95      0.96      0.96      2444\n",
            "           O       0.99      0.97      0.98      2612\n",
            "           P       0.98      0.99      0.98      2607\n",
            "           R       0.87      0.99      0.93      2659\n",
            "           S       0.99      0.99      0.99      2599\n",
            "           T       0.98      0.99      0.99      2700\n",
            "           U       0.99      0.85      0.91      2613\n",
            "           V       0.96      0.97      0.96      2604\n",
            "           W       0.99      0.99      0.99      2618\n",
            "           Y       0.99      1.00      0.99      2571\n",
            "\n",
            "    accuracy                           0.98     55231\n",
            "   macro avg       0.98      0.98      0.98     55231\n",
            "weighted avg       0.98      0.98      0.98     55231\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "all_preds = []\n",
        "all_targets = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_X, batch_y in test_loader:\n",
        "        outputs = model(batch_X)\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_targets.extend(batch_y.cpu().numpy())\n",
        "\n",
        "print(\"\\nEvaluación en el conjunto de prueba:\")\n",
        "target_names = label_encoder.classes_\n",
        "report = classification_report(all_targets, all_preds, target_names=target_names)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f00ccd1",
      "metadata": {
        "id": "2f00ccd1"
      },
      "source": [
        "**3. ¿El modelo está sub/sobreajustando los datos de entrenamiento?**\n",
        "\n",
        "  Para determinar si el modelo CNN está subajustando o sobreajustando los datos de entrenamiento, se analizaron las métricas de evaluación en los conjuntos de entrenamiento y validación durante las épocas de entrenamiento, así como el rendimiento final en el conjunto de prueba.\n",
        "  \n",
        "  Durante las 10 épocas de entrenamiento, se monitorearon la precisión en el entrenamiento (Train Acc), la precisión en la validación (Val Acc) y la pérdida en la validación (Val Loss).\n",
        "\n",
        "  Se observa que la precisión en el conjunto de entrenamiento y en el de validación son consistentemente cercanas a lo largo de las épocas, aumentando ambas de manera estable.\n",
        "\n",
        "  La pérdida de validación (Val Loss) disminuye consistentemente desde 0.2607 en la primera época hasta 0.0662 en la décima época, lo que indica que el modelo está generalizando bien a datos no vistos durante el entrenamiento.\n",
        "\n",
        "  El modelo alcanzó una precisión (accuracy) global del 98% en el conjunto de prueba. Este valor es muy cercano a la precisión de entrenamiento (98.10% en la última época) y a la precisión de validación (97.78% en la última época).\n",
        "\n",
        "* La pequeña diferencia entre las precisiones de entrenamiento, validación y prueba sugiere que el modelo no se ha memorizado los datos de entrenamiento a expensas de la generalización. La pérdida de validación no muestra una tendencia a aumentar, por lo cual no está sobreajuste.\n",
        "* Las altas precisiones obtenidas en todos los conjuntos (superiores al 97%) indican que el modelo tiene la capacidad suficiente para aprender la tarea de clasificación de manera efectiva y no está subajustado.\n",
        "\n",
        "**4. ¿Cuál es la métrica adecuada para este problema de negocio?**\n",
        "\n",
        "El problema de negocio consiste en la clasificación precisa de gestos estáticos de la Lengua de Señas Mexicana (LSM) a partir de datos de landmarks de la mano. El objetivo es desarrollar un sistema que pueda interpretar estas señas de manera fiable.\n",
        "\n",
        "El conjunto de métricas empleadas (Accuracy, Precision, Recall, F1-Score por clase, Macro F1 y Weighted F1) es exhaustivo y adecuado para este problema. Los valores consistentemente altos obtenidos demuestran un rendimiento sobresaliente y robusto del modelo empleado (CNN), tanto a nivel general como para cada letra individual.\n",
        "\n",
        "* Accuracy Global: Con 97%, es una métrica clave que muestra el éxito general.\n",
        "\n",
        "* F1-Score (Macro y Ponderado): Con valores de 0.98 para ambos, indican un rendimiento excelente y balanceado entre las clases.\n",
        "\n",
        "* Precision y Recall por Clase: Todas son muy altas, lo que significa que el modelo es fiable para cada letra individualmente.\n",
        "\n",
        "\n",
        "\n",
        "**5. ¿Cuál debería ser el desempeño mínimo a obtener?**\n",
        "\n",
        "El modelo CNN ha superado con creces tanto el desempeño mínimo esperado (>85%) y además el objetivo final del proyecto (>90%), alcanzando un accuracy en el conjunto de prueba del 98%. Este resultado no solo valida la efectividad del conjunto de características y la arquitectura del modelo para este dataset, sino que también establece un estándar alto de rendimiento para el proyecto.\n",
        "\n",
        "#### Conclusiones\n",
        "\n",
        "\n",
        "\n",
        "1.   El modelo de Red Neuronal Convolucional (CNN) implementado ha demostrado una alta efectividad para la clasificación de gestos estáticos de la Lengua de Señas Mexicana a partir de datos de puntos de referencia de la mano. Este enfoque se alinea con hallazgos previos que destacan la idoneidad de las CNN para tareas de reconocimiento de patrones espaciales en datos de señas.\n",
        "\n",
        "\n",
        "2. Los resultados de la evaluación indican que el modelo entrenado generaliza adecuadamente los datos. Las métricas de desempeño en el conjunto de validación durante el entrenamiento mostraron una convergencia estable, con una pérdida de validación que disminuyó consistentemente hasta las últimas épocas (Val Loss: 0.0746 en la época 9). Adicionalmente, la exactitud (accuracy) obtenida en el conjunto de prueba, que alcanzó un 0.98, junto con altos valores de precisión, recall y F1-score para la mayoría de las clases respalda la capacidad del modelo para realizar predicciones fiables.\n",
        "\n",
        "3. El desempeño alcanzado, con una exactitud global del 98% en el conjunto de prueba, posiciona al modelo como una base sólida para futuras investigaciones y potenciales aplicaciones en sistemas de traducción o asistencia para la Lengua de Señas Mexicana.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#### Referencias\n",
        "\n",
        "- Ansar, H., Ksibi, A., Jalal, A., Shorfuzzaman, M., Alsufyani, A., Alsuhibany, S. A., & Park, J. (2022). Dynamic hand gesture recognition for smart lifecare routines via K-ary tree hashing classifier. Applied Sciences, 12(13), 6481.\n",
        "- Zhou, Y., Zhao, K., Jin, L., & Zhan, C. (2024). End-to-End Video-Based Sign Language Recognition with CNN-Transformer Encoder-Decoder. arXiv.\n",
        "- Ramírez Sánchez, J. E., Anguiano Rodríguez, A., & González Mendoza, M. (2021). Interpretación en tiempo real de lengua de señas mexicana con CNN y HMM. Research in Computing Science, 150(6), 91–100."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hisepLw_TxGw"
      },
      "id": "hisepLw_TxGw",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}